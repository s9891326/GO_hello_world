# 第十二章練習題

## 練習 1：並發網頁爬蟲

創建一個高效的並發網頁爬蟲：

要求：
- 實現 URL 隊列管理
- 支援並發爬取（限制並發數）
- 實現重複 URL 檢測
- 添加爬取深度控制
- 支援爬取結果的收集和統計
- 實現優雅的停止機制

## 練習 2：任務調度器

實現一個靈活的任務調度系統：

要求：
- 支援定時任務和週期性任務
- 實現任務優先級管理
- 支援任務的動態添加和取消
- 實現任務執行狀態監控
- 支援任務執行結果回調
- 添加任務失敗重試機制

## 練習 3：生產者-消費者隊列

創建一個高性能的消息隊列系統：

要求：
- 支援多生產者多消費者
- 實現消息持久化（可選）
- 支援消息優先級
- 實現消費者組和負載均衡
- 添加消息確認機制
- 支援隊列監控和統計

## 練習 4：協程池管理器

設計一個智能的協程池管理系統：

要求：
- 動態調整池大小
- 實現協程復用和回收
- 支援不同類型的任務
- 添加協程健康檢查
- 實現池的監控和指標
- 支援優雅關閉

## 練習 5：並發數據處理器

實現一個大數據批處理系統：

要求：
- 支援數據分片處理
- 實現 Map-Reduce 模式
- 支援中間結果緩存
- 添加處理進度監控
- 實現錯誤處理和恢復
- 支援處理結果聚合

## 練習 6：實時數據流處理

創建一個實時數據流處理系統：

要求：
- 實現流式數據處理管道
- 支援窗口化操作（時間窗口、計數窗口）
- 實現流控制和背壓處理
- 添加數據質量檢查
- 支援流的分割和合並
- 實現實時指標計算

## 提示

1. 合理控制協程數量，避免資源耗盡
2. 使用 WaitGroup、Channel、Context 進行協程協調
3. 注意數據競爭和併發安全問題
4. 使用 select 語句處理多通道操作
5. 實現優雅的協程生命週期管理
6. 考慮使用 sync.Pool 復用對象

## 預期輸出範例

### 練習 1 輸出：
```
=== 並發網頁爬蟲測試 ===
啟動爬蟲，並發數: 5, 最大深度: 3

爬蟲統計：
  啟動 Worker: 5
  待爬取 URL: 127
  已處理 URL: 45
  重複 URL: 12
  失敗 URL: 3

Worker 狀態：
  Worker 1: 正在處理 https://example1.com
  Worker 2: 正在處理 https://example2.com  
  Worker 3: 空閒
  Worker 4: 正在處理 https://example3.com
  Worker 5: 空閒

爬取結果：
  總頁面: 45
  總鏈接: 1,234
  平均響應時間: 245ms
  成功率: 93.3%
```

### 練習 2 輸出：
```
=== 任務調度器測試 ===
調度器啟動，工作線程: 3

任務隊列：
  [高優先級] 數據備份 - 每日 02:00
  [中優先級] 報告生成 - 每週一 09:00  
  [低優先級] 日誌清理 - 每月 1 號

執行中任務：
  ⏰ 09:15:30 - 數據備份開始執行
  ⏰ 09:15:35 - 數據備份完成 (耗時: 5s)
  ⏰ 09:20:00 - 報告生成開始執行
  ❌ 09:20:15 - 報告生成失敗，將在 5 分鐘後重試

調度統計：
  今日執行任務: 12
  成功任務: 10
  失敗任務: 2
  平均執行時間: 45s
```

### 練習 4 輸出：
```
=== 協程池管理器測試 ===
初始化協程池，大小: 10

池狀態監控：
  時間: 14:30:15
  池大小: 15 (動態調整)
  活躍協程: 12
  空閒協程: 3
  排隊任務: 5
  
性能指標：
  任務吞吐量: 156 tasks/sec
  平均響應時間: 23ms
  協程利用率: 80%
  內存使用: 45MB

健康檢查：
  ✅ 所有協程響應正常
  ✅ 內存使用在正常範圍
  ⚠️ 排隊任務較多，建議增加池大小
```